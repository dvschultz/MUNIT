{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MUNIT.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dvschultz/MUNIT/blob/master/MUNIT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdC23munnMbJ",
        "colab_type": "text"
      },
      "source": [
        "#MUNIT\n",
        "MUNIT stands for Multimodal UNsupervised Image-to-image Translation. That’s a lot of words to say it can convert images of cats to images of dogs, or images of horses to images of zebras. Basically, it learns to convert one set of images (a “domain”) to another set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-bEjUkJjPAo",
        "colab_type": "code",
        "outputId": "b103fb5c-ee29-40ab-b91d-b65829f1d1cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "source": [
        "!git clone https://github.com/dvschultz/MUNIT\n",
        "\n",
        "#install dependencies\n",
        "!pip install torch torchvision tensorboard tensorboardX PyYAML torchfile\n",
        "%cd MUNIT"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'MUNIT'...\n",
            "remote: Enumerating objects: 26, done.\u001b[K\n",
            "remote: Counting objects: 100% (26/26), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 444 (delta 13), reused 0 (delta 0), pack-reused 418\u001b[K\n",
            "Receiving objects: 100% (444/444), 6.12 MiB | 9.73 MiB/s, done.\n",
            "Resolving deltas: 100% (225/225), done.\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.4.2)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (1.15.0)\n",
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/f1/5843425495765c8c2dd0784a851a93ef204d314fc87bcc2bbb9f662a3ad1/tensorboardX-2.0-py2.py3-none-any.whl (195kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 8.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (3.13)\n",
            "Collecting torchfile\n",
            "  Downloading https://files.pythonhosted.org/packages/91/af/5b305f86f2d218091af657ddb53f984ecbd9518ca9fe8ef4103a007252c9/torchfile-0.1.0.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.17.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (6.2.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (3.1.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (0.9.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (0.16.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard) (0.33.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (42.0.2)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (3.10.0)\n",
            "Requirement already satisfied: grpcio>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.15.0)\n",
            "Building wheels for collected packages: torchfile\n",
            "  Building wheel for torchfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchfile: filename=torchfile-0.1.0-cp36-none-any.whl size=5711 sha256=26b570ab36dc8ed307fa119decbff48427f70387bfd57f47196a52aabd569089\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/c3/d6/9a1cc8f3a99a0fc1124cae20153f36af59a6e683daca0a0814\n",
            "Successfully built torchfile\n",
            "Installing collected packages: tensorboardX, torchfile\n",
            "Successfully installed tensorboardX-2.0 torchfile-0.1.0\n",
            "/content/MUNIT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "My_COMHzkoYm",
        "colab_type": "text"
      },
      "source": [
        "#Dataset Preparation\n",
        "_Personally, I would not do training of MUNIT on Colab. Colab is slow and can quit after a couple hours—you’ll need more time than that to properly train a MUNIT model. I recommend training elsewhere and then jumping down to the Testing section here in Colab to test your model._\n",
        "\n",
        "MUNIT requires two different sets of images. Unlike Pix2Pix or similar models, these two sets of images do not need to be tightly coupled (for example: a color image and its grayscale equivalent). The images also do not need to be the same size.\n",
        "\n",
        "I recommend a minimum of ~250 images per folder. This will allow for the model to generalize fairly well (the more images, the better). \n",
        "\n",
        "Once you have created the images you will need to upload them to your server. The folder structure should look like this:\n",
        "* Top level folder name (I usually use X2Y, where X is the first dataset and Y is the second.)\n",
        "* ├ TrainA (training set from X)\n",
        "* ├ TrainB (training set from Y)\n",
        "* ├ TestA (testing set from X)\n",
        "* ├ TestB (testing set from Y)\n",
        "\n",
        "For our purposes TrainA/TestA and TrainB/TestB can be the same, but in a \"scientific\" setting you would want these folder to contain different images.\n",
        "\n",
        "There are two ways to upload the images.\n",
        "1. Zip up the folder and upload it to Colab in the `MUNIT/datasets` folder. This is probably slow and depending how large your dataset is can use up a lot of the Disk space in Colab.\n",
        "2. You can connect your Google Drive to Colab and host your files in Google Drive (This does not require you zipping up your folder, but does require a Google Drive account). This option needs a little setting up, but it saves you disk space and time once it’s set up.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHvMRr11tFo0",
        "colab_type": "code",
        "outputId": "e977cdf5-534b-4743-dc0d-60cea1730752",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "#Option 2: Connect your Google Drive to Colab.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "#after running this command you will need to click on a URL and copy the authorization code. Then come back here and pastr it in the field below"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w768srTWt1pd",
        "colab_type": "text"
      },
      "source": [
        "You could now have access to your Google Drive in the Files tab to the left of this text (Click on the left pointing error if your panel is collapsed.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AsDwtVNkl39",
        "colab_type": "text"
      },
      "source": [
        "#Training\n",
        "_I repeat: I do not recommend training on Colab. But here are the instructions if you know what you’re doing and really must._\n",
        "\n",
        "Once you have your dataset prepped and uploaded, the last thing to do is create a YAML config file. Let’s first duplicate one of the example files. In the code below I recommend renaming the file to match the top level folder name you used when uploading the dataset. This helps keep track of file naming and will remind you what settings you used should you need to retrain the model ever again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Anm_z5Djolg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b3623c0c-1ed9-4c5d-a935-005a6b626ee4"
      },
      "source": [
        "pwd"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/MUNIT'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuIynNtN7wMO",
        "colab_type": "text"
      },
      "source": [
        "#Testing\n",
        "If you’re only using Colab for testing, you’ll need to do the following:\n",
        "1. Move your config .yaml from training into the `configs` folder.\n",
        "2. Create a `models` folder and put the generator .pt file in there (the generator file begins with `gen_`)\n",
        "3. Create an `inputs` folder and a `styles` folder. You’ll put images you want to translate in the `inputs` folder and images you want to guide style in the `styles` folder (See the Guided Translation)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hqj4Ge1NKkJ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#make some folders (only run once)\n",
        "%mkdir models\n",
        "%mkdir styles"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDLNbUxV7xkV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#testing with a single image\n",
        "#this generates 10 random images from the model\n",
        "!python test.py --config /content/MUNIT/configs/512-sm_birds2floralmag_folder.yaml --input /content/MUNIT/inputs/birdsAustraliav5Goul_0208.png --output_folder outputs --checkpoint /content/MUNIT/models/gen_00150000.pt --a2b 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4rRLZ39V9Tz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bdc9f039-573a-4d74-cee4-5dfc6719a003"
      },
      "source": [
        "!zip -r outputs.zip ./outputs"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "updating: outputs/ (stored 0%)\n",
            "updating: outputs/output004.jpg (deflated 1%)\n",
            "updating: outputs/output006.jpg (deflated 3%)\n",
            "updating: outputs/output002.jpg (deflated 1%)\n",
            "updating: outputs/output009.jpg (deflated 1%)\n",
            "updating: outputs/output007.jpg (deflated 1%)\n",
            "updating: outputs/output005.jpg (deflated 2%)\n",
            "updating: outputs/output000.jpg (deflated 3%)\n",
            "updating: outputs/output001.jpg (deflated 1%)\n",
            "updating: outputs/output003.jpg (deflated 1%)\n",
            "updating: outputs/output008.jpg (deflated 0%)\n",
            "updating: outputs/input.jpg (deflated 1%)\n",
            "updating: outputs/output069.jpg (deflated 2%)\n",
            "updating: outputs/output077.jpg (deflated 2%)\n",
            "updating: outputs/output091.jpg (deflated 1%)\n",
            "updating: outputs/output037.jpg (deflated 1%)\n",
            "updating: outputs/output032.jpg (deflated 2%)\n",
            "updating: outputs/output065.jpg (deflated 3%)\n",
            "updating: outputs/output087.jpg (deflated 1%)\n",
            "updating: outputs/output013.jpg (deflated 1%)\n",
            "updating: outputs/output088.jpg (deflated 1%)\n",
            "updating: outputs/output040.jpg (deflated 1%)\n",
            "updating: outputs/output094.jpg (deflated 0%)\n",
            "updating: outputs/output018.jpg (deflated 0%)\n",
            "updating: outputs/output075.jpg (deflated 1%)\n",
            "updating: outputs/output039.jpg (deflated 1%)\n",
            "updating: outputs/output026.jpg (deflated 1%)\n",
            "updating: outputs/output083.jpg (deflated 2%)\n",
            "updating: outputs/output061.jpg (deflated 2%)\n",
            "updating: outputs/output064.jpg (deflated 1%)\n",
            "updating: outputs/output027.jpg (deflated 2%)\n",
            "updating: outputs/output085.jpg (deflated 2%)\n",
            "updating: outputs/output038.jpg (deflated 2%)\n",
            "updating: outputs/output016.jpg (deflated 1%)\n",
            "updating: outputs/output053.jpg (deflated 1%)\n",
            "updating: outputs/output098.jpg (deflated 2%)\n",
            "updating: outputs/output050.jpg (deflated 1%)\n",
            "updating: outputs/output079.jpg (deflated 1%)\n",
            "updating: outputs/output097.jpg (deflated 1%)\n",
            "updating: outputs/output048.jpg (deflated 3%)\n",
            "updating: outputs/output036.jpg (deflated 2%)\n",
            "updating: outputs/output017.jpg (deflated 1%)\n",
            "updating: outputs/output025.jpg (deflated 2%)\n",
            "updating: outputs/output014.jpg (deflated 2%)\n",
            "updating: outputs/output086.jpg (deflated 3%)\n",
            "updating: outputs/output058.jpg (deflated 1%)\n",
            "updating: outputs/output066.jpg (deflated 3%)\n",
            "updating: outputs/output080.jpg (deflated 1%)\n",
            "updating: outputs/output011.jpg (deflated 3%)\n",
            "updating: outputs/output054.jpg (deflated 1%)\n",
            "updating: outputs/output046.jpg (deflated 2%)\n",
            "updating: outputs/output060.jpg (deflated 2%)\n",
            "updating: outputs/output070.jpg (deflated 1%)\n",
            "updating: outputs/output022.jpg (deflated 2%)\n",
            "updating: outputs/output023.jpg (deflated 1%)\n",
            "updating: outputs/output081.jpg (deflated 1%)\n",
            "updating: outputs/output095.jpg (deflated 1%)\n",
            "updating: outputs/output068.jpg (deflated 2%)\n",
            "updating: outputs/output015.jpg (deflated 0%)\n",
            "updating: outputs/output010.jpg (deflated 2%)\n",
            "updating: outputs/output031.jpg (deflated 1%)\n",
            "updating: outputs/output029.jpg (deflated 2%)\n",
            "updating: outputs/output099.jpg (deflated 0%)\n",
            "updating: outputs/output056.jpg (deflated 3%)\n",
            "updating: outputs/output051.jpg (deflated 2%)\n",
            "updating: outputs/output012.jpg (deflated 1%)\n",
            "updating: outputs/output028.jpg (deflated 1%)\n",
            "updating: outputs/output034.jpg (deflated 0%)\n",
            "updating: outputs/output074.jpg (deflated 2%)\n",
            "updating: outputs/output045.jpg (deflated 1%)\n",
            "updating: outputs/output020.jpg (deflated 3%)\n",
            "updating: outputs/output089.jpg (deflated 1%)\n",
            "updating: outputs/output071.jpg (deflated 2%)\n",
            "updating: outputs/output059.jpg (deflated 2%)\n",
            "updating: outputs/output021.jpg (deflated 0%)\n",
            "updating: outputs/output049.jpg (deflated 1%)\n",
            "updating: outputs/output052.jpg (deflated 1%)\n",
            "updating: outputs/output042.jpg (deflated 0%)\n",
            "updating: outputs/output047.jpg (deflated 2%)\n",
            "updating: outputs/output019.jpg (deflated 3%)\n",
            "updating: outputs/output055.jpg (deflated 2%)\n",
            "updating: outputs/output093.jpg (deflated 1%)\n",
            "updating: outputs/output067.jpg (deflated 1%)\n",
            "updating: outputs/output090.jpg (deflated 1%)\n",
            "updating: outputs/output044.jpg (deflated 1%)\n",
            "updating: outputs/output030.jpg (deflated 2%)\n",
            "updating: outputs/output082.jpg (deflated 2%)\n",
            "updating: outputs/output057.jpg (deflated 2%)\n",
            "updating: outputs/output096.jpg (deflated 1%)\n",
            "updating: outputs/output035.jpg (deflated 1%)\n",
            "updating: outputs/output033.jpg (deflated 2%)\n",
            "updating: outputs/output041.jpg (deflated 2%)\n",
            "updating: outputs/output072.jpg (deflated 1%)\n",
            "updating: outputs/output063.jpg (deflated 2%)\n",
            "updating: outputs/output062.jpg (deflated 1%)\n",
            "updating: outputs/output073.jpg (deflated 2%)\n",
            "updating: outputs/output043.jpg (deflated 2%)\n",
            "updating: outputs/output076.jpg (deflated 1%)\n",
            "updating: outputs/output092.jpg (deflated 1%)\n",
            "updating: outputs/output078.jpg (deflated 1%)\n",
            "updating: outputs/output084.jpg (deflated 1%)\n",
            "updating: outputs/output024.jpg (deflated 3%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGaL9GJpRbWb",
        "colab_type": "text"
      },
      "source": [
        "##Testing Options\n",
        "\n",
        "`--num_style`\n",
        "How many \"styles\" do you want to output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43-pBsOtaKEs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#testing with a single image, use --num_styles to set the number of styles\n",
        "!python test.py --config /content/MUNIT/configs/512-sm_birds2floralmag_folder.yaml --input /content/MUNIT/inputs/birdsAustraliav5Goul_0212.png --output_folder outputs --checkpoint /content/MUNIT/models/gen_00150000.pt --a2b 1 --num_style 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbQcv9R9941U",
        "colab_type": "text"
      },
      "source": [
        "##Guided Translation\n",
        "MUNIT also allows you to do what they call \"guided translation.\" This allows you to pass it an image and use that image as the \"style\" (for lack of a better term) for the output image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMC-YqZy98-M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#guided translation\n",
        "python test.py --config configs/edges2shoes_folder.yaml --input inputs/edges2shoes_edge.jpg --output_folder results --checkpoint models/edges2shoes.pt --a2b 1 --style inputs/edges2shoes_shoe.jpg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V44wD5Gq-0Sc",
        "colab_type": "text"
      },
      "source": [
        "##Batch Testing\n",
        "Both of the above examples only generate samples from one image. If you want to test it on a whole folder of images you use the `test_batch.py` script.\n",
        "\n",
        "Note: you can’t currently batch test with a guided translation image. (I’m working on it.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Btb7kiV9_0SC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "python test_batch.py --config configs/edges2shoes_folder.yaml --input_folder inputs --output_folder outputs --checkpoint models/edges2shoes.pt --a2b 1"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
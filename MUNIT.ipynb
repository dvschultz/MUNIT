{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MUNIT.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dvschultz/MUNIT/blob/master/MUNIT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdC23munnMbJ",
        "colab_type": "text"
      },
      "source": [
        "#MUNIT\n",
        "MUNIT stands for Multimodal UNsupervised Image-to-image Translation. That’s a lot of words to say it can convert images of cats to images of dogs, or images of horses to images of zebras. Basically, it learns to convert one set of images (a “domain”) to another set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-bEjUkJjPAo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "7892d14f-356d-4e81-cd13-cff00a86ac68"
      },
      "source": [
        "!git clone https://github.com/dvschultz/MUNIT"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'MUNIT'...\n",
            "remote: Enumerating objects: 418, done.\u001b[K\n",
            "remote: Total 418 (delta 0), reused 0 (delta 0), pack-reused 418\u001b[K\n",
            "Receiving objects: 100% (418/418), 6.11 MiB | 4.09 MiB/s, done.\n",
            "Resolving deltas: 100% (212/212), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBgM0nw2jUOI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "da00e650-30c5-4b48-fd9e-5f9a357f18f7"
      },
      "source": [
        "#install dependencies\n",
        "!pip install torch torchvision tensorboard tensorboardX PyYAML\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.17.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (1.15.0)\n",
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/f1/5843425495765c8c2dd0784a851a93ef204d314fc87bcc2bbb9f662a3ad1/tensorboardX-2.0-py2.py3-none-any.whl (195kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (0.8.1)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.17.4)\n",
            "Requirement already satisfied: grpcio>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard) (0.33.6)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.12.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (0.16.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (42.0.2)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (3.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (3.1.1)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.0\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (3.13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "My_COMHzkoYm",
        "colab_type": "text"
      },
      "source": [
        "#Dataset Preparation\n",
        "_Personally, I would do training of MUNIT on something over than Colab. Colab is slow and can quit after a couple hours—you’ll need more time than that to properly train a MUNIT model. I recommend training elsewhere and then jumping down to the Testing section here in Colab to test your model._\n",
        "\n",
        "MUNIT requires two different sets of images. Unlike Pix2Pix or similar models, these two sets of images do not need to be tightly coupled (for example: a color image and its grayscale equivalent). The images also do not need to be the same size.\n",
        "\n",
        "I recommend a minimum of ~250 images per folder. This will allow for the model to generalize fairly well (the more images, the better). \n",
        "\n",
        "Once you have created the images you will need to upload them to your server. The folder structure should look like this:\n",
        "* Top level folder name (I usually use X2Y, where X is the first dataset and Y is the second.)\n",
        "* ├ TrainA (training set from X)\n",
        "* ├ TrainB (training set from Y)\n",
        "* ├ TestA (testing set from X)\n",
        "* ├ TestB (testing set from Y)\n",
        "\n",
        "For our purposes TrainA/TestA and TrainB/TestB can be the same, but in a \"scientific\" setting you would want these folder to contain different images.\n",
        "\n",
        "There are two ways to upload the images.\n",
        "1. Zip up the folder and upload it to Colab in the `MUNIT/datasets` folder. This is probably slow and depending how large your dataset is can use up a lot of the Disk space in Colab.\n",
        "2. You can connect your Google Drive to Colab and host your files in Google Drive (This does not require you zipping up your folder, but does require a Google Drive account). This option needs a little setting up, but it saves you disk space and time once it’s set up.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHvMRr11tFo0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e0d39db2-0319-4c73-dffa-3afa21875a94"
      },
      "source": [
        "#Option 2: Connect your Google Drive to Colab.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "#after running this command you will need to click on a URL and copy the authorization code. Then come back here and pastr it in the field below"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w768srTWt1pd",
        "colab_type": "text"
      },
      "source": [
        "You could now have access to your Google Drive in the Files tab to the left of this text (Click on the left pointing error if your panel is collapsed.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AsDwtVNkl39",
        "colab_type": "text"
      },
      "source": [
        "#Training\n",
        "_I repeat: I do not recommend training on Colab. But here are the instructions if you know what you’re doing and really must._\n",
        "\n",
        "Once you have your dataset prepped and uploaded, the last thing to do is create a YAML config file. Let’s first duplicate one of the example files. In the code below I recommend renaming the file to match the top level folder name you used when uploading the dataset. This helps keep track of file naming and will remind you what settings you used should you need to retrain the model ever again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Anm_z5Djolg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}